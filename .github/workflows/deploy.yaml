name: Deploy to Cloud Server

on:
  push:
    branches: [ main, master ]
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: Build Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: false
        load: true
        tags: lingua-ai:latest
        cache-from: type=gha
        cache-to: type=gha,mode=max
        
    - name: Run tests
      run: |
        go test ./...
        
    - name: Deploy to cloud server
      if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
      uses: appleboy/ssh-action@v1.0.3
      with:
        host: ${{ secrets.SERVER_HOST }}
        username: ${{ secrets.SERVER_USERNAME }}
        password: ${{ secrets.SERVER_PASSWORD }}
        port: ${{ secrets.SERVER_PORT || '22' }}
        script: |
          # Создаем директорию для приложения
          sudo mkdir -p /opt/lingua-ai
          sudo chown $USER:$USER /opt/lingua-ai
          cd /opt/lingua-ai
          
          # Останавливаем текущие контейнеры
          docker-compose down || true
          
          # Создаем .env файл с переменными окружения
          cat > .env << 'EOF'
          # Telegram Bot Configuration
          TELEGRAM_BOT_TOKEN=${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_WEBHOOK_URL=${{ secrets.TELEGRAM_WEBHOOK_URL }}
          
          # AI Provider Configuration
          AI_PROVIDER=${{ secrets.AI_PROVIDER || 'deepseek' }}
          AI_MODEL=${{ secrets.AI_MODEL || 'deepseek-chat' }}
          AI_MAX_TOKENS=${{ secrets.AI_MAX_TOKENS || '1000' }}
          AI_TEMPERATURE=${{ secrets.AI_TEMPERATURE || '0.7' }}
          
          # DeepSeek Configuration
          DEEPSEEK_API_KEY=${{ secrets.DEEPSEEK_API_KEY }}
          DEEPSEEK_BASE_URL=${{ secrets.DEEPSEEK_BASE_URL || 'https://api.deepseek.com/v1' }}
          
          # OpenRouter Configuration
          OPENROUTER_API_KEY=${{ secrets.OPENROUTER_API_KEY }}
          OPENROUTER_SITE_URL=${{ secrets.OPENROUTER_SITE_URL || 'https://lingua-ai.ru' }}
          OPENROUTER_SITE_NAME=${{ secrets.OPENROUTER_SITE_NAME || 'Lingua AI' }}
          
          # Whisper Configuration
          WHISPER_API_URL=http://whisper:9000
          WHISPER_MODEL=${{ secrets.WHISPER_MODEL || 'small' }}
          WHISPER_COMPUTE=${{ secrets.WHISPER_COMPUTE || 'int8' }}
          
          # Database Configuration
          DB_HOST=postgres
          DB_PORT=5432
          DB_USER=lingua_user
          DB_PASSWORD=lingua_password
          DB_NAME=lingua_ai
          DB_SSL_MODE=disable
          
          # Application Configuration
          APP_ENV=production
          LOG_LEVEL=${{ secrets.LOG_LEVEL || 'info' }}
          APP_PORT=8080
          
          # YooKassa Configuration
          YUKASSA_SHOP_ID=${{ secrets.YUKASSA_SHOP_ID }}
          YUKASSA_SECRET_KEY=${{ secrets.YUKASSA_SECRET_KEY }}
          YUKASSA_TEST_MODE=${{ secrets.YUKASSA_TEST_MODE || 'false' }}
          EOF
          
          # Копируем Dockerfile
          cat > Dockerfile << 'EOF'
          # Используем официальный образ Go (последняя версия)
          FROM golang:1.23-alpine AS builder
          
          # Устанавливаем необходимые пакеты
          RUN apk add --no-cache git ca-certificates tzdata
          
          # Устанавливаем рабочую директорию
          WORKDIR /app
          
          # Копируем файлы зависимостей
          COPY go.mod go.sum ./
          
          # Загружаем зависимости
          RUN go mod download
          
          # Копируем исходный код
          COPY . .
          
          # Собираем приложение
          RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o main ./cmd
          
          # Финальный образ
          FROM alpine:latest
          
          # Устанавливаем необходимые пакеты
          RUN apk --no-cache add ca-certificates tzdata
          
          # Создаем пользователя для безопасности
          RUN addgroup -g 1001 -S appgroup && \
              adduser -u 1001 -S appuser -G appgroup
          
          # Устанавливаем рабочую директорию
          WORKDIR /app
          
          # Копируем бинарный файл из builder
          COPY --from=builder /app/main .
          
          # Копируем миграции
          COPY --from=builder /app/scripts ./scripts
          
          # Создаем директорию для логов
          RUN mkdir -p /app/logs && \
              chown -R appuser:appgroup /app
          
          # Переключаемся на непривилегированного пользователя
          USER appuser
          
          # Открываем порт (если понадобится для health check)
          EXPOSE 8080
          
          # Запускаем приложение
          CMD ["./main"]
          EOF
          
          # Копируем docker-compose.yml (без version)
          cat > docker-compose.yml << 'EOF'
          services:
            postgres:
              image: postgres:15-alpine
              container_name: lingua-ai-postgres
              environment:
                POSTGRES_DB: lingua_ai
                POSTGRES_USER: lingua_user
                POSTGRES_PASSWORD: lingua_password
              volumes:
                - postgres_data:/var/lib/postgresql/data
                - ./scripts/migrations:/docker-entrypoint-initdb.d
              ports:
                - "5432:5432"
              restart: unless-stopped
              healthcheck:
                test: ["CMD-SHELL", "pg_isready -U lingua_user -d lingua_ai"]
                interval: 30s
                timeout: 10s
                retries: 3
              
            whisper:
              image: onerahmet/openai-whisper-asr-webservice:latest
              container_name: whisper
              ports:
                - "8081:9000"
              environment:
                ASR_MODEL: small
                ASR_TASK: transcribe
                ASR_DEVICE: cpu
                ASR_COMPUTE_TYPE: int8
              restart: unless-stopped
              healthcheck:
                test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9000/"]
                interval: 30s
                timeout: 10s
                retries: 3
              
            app:
              build: .
              container_name: lingua-ai-app
              ports:
                - "8080:8080"
              depends_on:
                postgres:
                  condition: service_healthy
                whisper:
                  condition: service_healthy
              restart: unless-stopped
              healthcheck:
                test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health"]
                interval: 30s
                timeout: 10s
                retries: 3
              
          volumes:
            postgres_data:
              driver: local
          EOF
          
          # Создаем директорию для скриптов
          mkdir -p scripts/migrations
          
          # Копируем миграции из репозитория
          if [ -d "/tmp/scripts" ]; then
            cp -r /tmp/scripts/* scripts/
          fi
          
          # Проверяем, что Docker Compose установлен
          docker-compose --version
          
          # Запускаем контейнеры
          docker-compose up -d
          
          # Ждем запуска и проверяем статус
          sleep 30
          docker-compose ps
          
          # Проверяем health check
          curl -f http://localhost:8080/health || exit 1
          
          echo "✅ Deployment completed successfully!"